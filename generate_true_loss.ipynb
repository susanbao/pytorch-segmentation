{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f7ef5a8f-c87e-41d0-be66-cc47746c22f1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import numpy as np\n",
    "from utils import losses\n",
    "import torch\n",
    "from utils.utils import *\n",
    "from scipy.special import softmax\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88c9864f-300e-47b6-8cf7-30a4f0085023",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# PSPNet_VOC, UNet_COCO10k\n",
    "base_path = \"./pro_data/UNet_COCO10k/val/\"\n",
    "files = os.listdir(base_path + \"output\")\n",
    "cross_entropy_loss_func = losses.CrossEntropyLoss2d(reduction=\"none\")\n",
    "file_count = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d94e2f7d-c9da-451b-b36b-dd4680133952",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "199\n",
      "299\n",
      "399\n",
      "499\n",
      "599\n",
      "699\n",
      "799\n",
      "899\n",
      "999\n",
      "1099\n"
     ]
    }
   ],
   "source": [
    "check_folder_exist(base_path + \"loss\")\n",
    "for file in range(file_count):\n",
    "    output = np_read(base_path + f\"output/{file}.npy\")\n",
    "    target = np_read(base_path + f\"target/{file}.npy\")\n",
    "    losses = cross_entropy_loss_func(torch.from_numpy(output), torch.from_numpy(target))\n",
    "    losses = losses.numpy()\n",
    "    np_write(losses, base_path + f\"loss/{file}.npy\")\n",
    "    if (file+1)%100 == 0:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "c1d134d8-3341-4609-a6b8-134ba8dabeed",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file = files[0]\n",
    "output = np_read(base_path + f\"output/{file}\")\n",
    "target = np_read(base_path + f\"target/{file}\")\n",
    "image = np_read(base_path + f\"image/{file}\")\n",
    "losses = cross_entropy_loss_func(torch.from_numpy(output), torch.from_numpy(target))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b00ef42d-3f91-48bb-9617-a8003c7e356d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.matshow(losses[0])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b77c94e-e6af-432e-8827-9ce0aae3464c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.matshow(target[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56986ca2-004b-429e-9d44-a5c0aec5082d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.matshow(losses[2])\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d685a654-dfb2-424f-93e2-24161904c9bb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.matshow(target[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d74af71-f015-4111-9b03-a4fc09c0b000",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.matshow(image[2,1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "bb6389fa-8280-48ee-86dd-5d6b50b27847",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "output_label = np.argmax(output, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cbfb15d-a812-46b5-aecf-65e42057f87b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "plt.matshow(output_label[2])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05356ae8-0b0d-4dee-a541-425cc9789f42",
   "metadata": {},
   "source": [
    "## Generate ground truth image-based loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "19cff7cb-e47f-4c42-9ebb-fdb1e6e41932",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "199\n",
      "299\n",
      "399\n",
      "499\n",
      "599\n",
      "699\n",
      "799\n",
      "899\n",
      "999\n",
      "1099\n"
     ]
    }
   ],
   "source": [
    "base_path = \"./pro_data/UNet_COCO10k/train/\"\n",
    "files = os.listdir(base_path + \"loss\")\n",
    "file_count = len(files)\n",
    "true_losses = None\n",
    "for file in range(file_count):\n",
    "    losses = np_read(base_path + f\"loss/{file}.npy\")\n",
    "    losses = np.reshape(losses, (losses.shape[0], -1))\n",
    "    losses = np.mean(losses, axis=1)\n",
    "    if true_losses is None:\n",
    "        true_losses = losses\n",
    "    else:\n",
    "        true_losses = np.concatenate((true_losses, losses), axis=0)\n",
    "    if (file+1)%100 == 0:\n",
    "        print(file)\n",
    "np_write(true_losses, base_path + \"image_true_losses.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec9a43e3-cd17-4699-8c08-6475b6d544e9",
   "metadata": {},
   "source": [
    "## Generate ground truth region-baed loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ec690541-601e-40d1-b919-02403fa896c9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## region 8x8\n",
    "base_path = \"./pro_data/UNet_COCO10k/val/\"\n",
    "files = os.listdir(base_path + \"output\")\n",
    "file_count = len(files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8bc9eb08-2fe9-4a2f-ac77-2104134a971c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((60,60))\n",
    "region_based_losses = None\n",
    "for file in range(file_count):\n",
    "    losses = np_read(base_path + f\"loss/{file}.npy\")\n",
    "    losses = torch.from_numpy(losses)\n",
    "    losses = avgpool(losses)\n",
    "    losses = losses.numpy()\n",
    "    losses = losses.reshape(-1)\n",
    "    if region_based_losses is None:\n",
    "        region_based_losses = losses\n",
    "    else:\n",
    "        region_based_losses = np.concatenate((region_based_losses, losses), axis=0)\n",
    "    if (file+1)%100 == 0:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b41569c5-3774-457c-bc7c-05c83b37f80c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_write(region_based_losses, base_path + \"region_8_8_true_losses.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "c2fb4feb-5741-46f2-b27f-105f49c26ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "## region 16x16\n",
    "import torch\n",
    "base_path = \"./pro_data/UNet_COCO10k/val/\"\n",
    "files = os.listdir(base_path + \"output\")\n",
    "file_count = len(files)\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((30,30))\n",
    "region_based_losses = None\n",
    "for file in range(file_count):\n",
    "    losses = np_read(base_path + f\"loss/{file}.npy\")\n",
    "    losses = torch.from_numpy(losses)\n",
    "    losses = avgpool(losses)\n",
    "    losses = losses.numpy()\n",
    "    losses = losses.reshape(-1)\n",
    "    if region_based_losses is None:\n",
    "        region_based_losses = losses\n",
    "    else:\n",
    "        region_based_losses = np.concatenate((region_based_losses, losses), axis=0)\n",
    "    if (file+1)%100 == 0:\n",
    "        print(file)\n",
    "np_write(region_based_losses, base_path + \"region_16_16_true_losses.npy\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "559ea7cb-5132-4be9-9237-1d813114b343",
   "metadata": {},
   "source": [
    "## Entropy part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0729e87b-064d-47c8-80e2-0c0a5c2fad5c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n"
     ]
    }
   ],
   "source": [
    "# PSPNet_VOC, UNet_COCO10k\n",
    "base_path = \"./pro_data/PSPNet_VOC/train/\"\n",
    "files = os.listdir(base_path + \"output\")\n",
    "file_count = len(files)\n",
    "\n",
    "check_folder_exist(base_path + \"entropy\")\n",
    "for file in range(file_count):\n",
    "    output = np_read(base_path + f\"output/{file}.npy\")\n",
    "    output = torch.from_numpy(output)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    entropy = torch.sum(torch.mul(-output, torch.log(output + 1e-20)), dim=1).unsqueeze(dim=1)\n",
    "    np_write(entropy.numpy(), base_path + f\"entropy/{file}.npy\")\n",
    "    if (file+1)%100 == 0:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff966ad-e66e-4947-a957-e2d986ea4626",
   "metadata": {},
   "source": [
    "## Feature Part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f7c5fd4-e00a-4f1e-afef-5b9c12018ea5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "99\n",
      "199\n",
      "299\n",
      "399\n",
      "499\n",
      "599\n",
      "699\n",
      "799\n",
      "899\n",
      "999\n",
      "1099\n"
     ]
    }
   ],
   "source": [
    "# PSPNet_VOC, UNet_COCO10k\n",
    "base_path = \"./pro_data/UNet_COCO10k/train/\"\n",
    "files = os.listdir(base_path + \"output\")\n",
    "file_count = len(files)\n",
    "\n",
    "check_folder_exist(base_path + \"feature\")\n",
    "for file in range(file_count):\n",
    "    output = np_read(base_path + f\"output/{file}.npy\")\n",
    "    output = torch.from_numpy(output)\n",
    "    output = F.softmax(output, dim=1)\n",
    "    np_write(output.numpy(), base_path + f\"feature/{file}.npy\")\n",
    "    if (file+1)%100 == 0:\n",
    "        print(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "698d4a47-370d-493f-8afe-de5c3103f9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "file = 17\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((60,60))\n",
    "losses = np_read(base_path + f\"loss/{file}.npy\")\n",
    "losses = torch.from_numpy(losses)\n",
    "losses = avgpool(losses)\n",
    "losses = losses.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "db788ca4-af88-4b92-8877-f0a2e669d85c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0005, 0.0002, 0.0002, 0.0002, 0.0002, 0.0006, 0.0017, 0.0036, 0.0041,\n",
       "        0.0022])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5dfde6cc-90e4-491a-9666-55d804ae5518",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "region_losses = np_read(base_path + \"region_8_8_true_losses.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a5f9b915-da14-4a2a-8aba-b1129e165fe6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00047702, 0.00017212, 0.00016255, 0.00016966, 0.00023114,\n",
       "       0.00060023, 0.00171918, 0.00357157, 0.00408929, 0.00224719],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_losses[losses.shape[0] * file:losses.shape[0] * file+10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf228a85-91ae-43b7-916f-ab23a9f20e6b",
   "metadata": {},
   "source": [
    "## Generate 4 splited loss ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5b4995fc-dd42-4047-aaf2-20b6e8b69480",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = \"./pro_data/PSPNet_VOC/val/\"\n",
    "files = os.listdir(base_path + \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "101b60ae-9cd5-4c5d-af20-6ce77e1228a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((2,2))\n",
    "region_based_losses = None\n",
    "for file in files:\n",
    "    losses = np_read(base_path + f\"loss/{file}\")\n",
    "    losses = torch.from_numpy(losses)\n",
    "    losses = avgpool(losses)\n",
    "    losses = losses.numpy()\n",
    "    losses = losses.reshape(-1)\n",
    "    if region_based_losses is None:\n",
    "        region_based_losses = losses\n",
    "    else:\n",
    "        region_based_losses = np.concatenate((region_based_losses, losses), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "8532c7d3-98b7-49c8-95b1-0408e2d586c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_write(region_based_losses, base_path + \"image_split_2_2_true_losses.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c337f51c-023d-4940-a345-37ac60e6f81e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1.0793692, 0.0)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_based_losses.max(), region_based_losses.min()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e68e2fe-519b-4ba4-9614-4f716ed82995",
   "metadata": {},
   "source": [
    "## Generate 8x8 patch ground truth for 4 splited image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b13ce5bb-29b6-4af5-98f5-3292f8d801f4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "base_path = \"./pro_data/PSPNet_VOC/val/\"\n",
    "files = os.listdir(base_path + \"output\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e203945b-f5d0-4c83-a271-d7752a74e7ef",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((60,60))\n",
    "splited_location_list = [[0,30,0,30], [0,30,30,60],[30,60,0,30],[30,60,30,60]]\n",
    "region_based_losses = None\n",
    "for file in files:\n",
    "    losses = np_read(base_path + f\"loss/{file}\")\n",
    "    losses = torch.from_numpy(losses)\n",
    "    losses = avgpool(losses)\n",
    "    losses = losses.numpy()\n",
    "    for i in range(losses.shape[0]):\n",
    "        for j in range(4):\n",
    "            location = splited_location_list[j]\n",
    "            loss = losses[i, location[0]:location[1],location[2]:location[3]]\n",
    "            loss = loss.reshape(-1)\n",
    "            if region_based_losses is None:\n",
    "                region_based_losses = loss\n",
    "            else:\n",
    "                region_based_losses = np.concatenate((region_based_losses, loss), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "fe520ea3-034f-44ae-b7e2-3b6393a9e3ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "np_write(region_based_losses, base_path + \"region_8_8_image_split_true_losses.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "e0fe99bd-6e0e-4445-8b2a-e220625a85d6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((5216400,), 10.661509, 0.0)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "region_based_losses.shape, region_based_losses.max(), region_based_losses.min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79168644-4b31-433f-a6db-da18876b3e59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
