{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd81cf72-4fdc-468f-a1eb-01548c57701c",
   "metadata": {},
   "source": [
    "# Active Testing\n",
    "data stored in ./pro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ffd0254d-77c6-4946-92aa-2e75a916dc67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f5c5306c-2310-4043-82fe-3c234d5f87a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LURE_weights_for_risk_estimator(weights, N):\n",
    "    M = weights.size\n",
    "    if M < N:\n",
    "        m = np.arange(1, M+1)\n",
    "        v = (\n",
    "            1\n",
    "            + (N-M)/(N-m) * (\n",
    "                    1 / ((N-m+1) * weights)\n",
    "                    - 1\n",
    "                    )\n",
    "            )\n",
    "    else:\n",
    "        v = 1\n",
    "\n",
    "    return v\n",
    "\n",
    "def acquire(expected_loss_inputs, samples_num):\n",
    "    assert samples_num <= expected_loss_inputs.size\n",
    "    expected_loss = np.copy(expected_loss_inputs)\n",
    "    # Log-lik can be negative.\n",
    "    # Make all values positive.\n",
    "    if (expected_loss < 0).sum() > 0:\n",
    "        expected_loss += np.abs(expected_loss.min())\n",
    "    \n",
    "    if np.any(np.isnan(expected_loss)):\n",
    "        logging.warning(\n",
    "            'Found NaN values in expected loss, replacing with 0.')\n",
    "        logging.info(f'{expected_loss}')\n",
    "        expected_loss = np.nan_to_num(expected_loss, nan=0)\n",
    "    pick_sample_idxs = np.zeros((samples_num), dtype = int)\n",
    "    idx_array = np.arange(expected_loss.size)\n",
    "    weights = np.zeros((samples_num), dtype = np.single)\n",
    "    uniform_clip_val = 0.2\n",
    "    for i in range(samples_num):\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        # clip all values less than 10 percent of uniform propability\n",
    "        expected_loss = np.maximum(uniform_clip_val * 1/expected_loss.size, expected_loss)\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        sample = np.random.multinomial(1, expected_loss)\n",
    "        cur_idx = np.where(sample)[0][0]\n",
    "        # cur_idx = np.random.randint(expected_loss.size)\n",
    "        pick_sample_idxs[i] = idx_array[cur_idx]\n",
    "        weights[i] = expected_loss[cur_idx]\n",
    "        selected_mask = np.ones((expected_loss.size), dtype=bool)\n",
    "        selected_mask[cur_idx] = False\n",
    "        expected_loss = expected_loss[selected_mask]\n",
    "        idx_array = idx_array[selected_mask]\n",
    "    return pick_sample_idxs, weights\n",
    "\n",
    "def run_one_random_sample_risk_estimator(true_losses, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    perm = np.random.permutation(true_losses.size)\n",
    "    pick_sample_idxs = perm[:samples_num]\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "    return float(sampled_true_losses.mean())\n",
    "\n",
    "def run_one_active_test_risk_estimator(true_losses, expected_losses, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pick_sample_idxs, weights = acquire(expected_losses, samples_num)\n",
    "    risk_estimator_weights = LURE_weights_for_risk_estimator(weights, expected_losses.size)\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "\n",
    "    loss_risk = (sampled_true_losses * risk_estimator_weights).mean()\n",
    "    return float(loss_risk)\n",
    "\n",
    "def active_testing(file_path, true_losses, expected_losses, active_test_type):\n",
    "    json_object = {}\n",
    "    for sample_size in sample_size_set:\n",
    "        for seed in random_seed_set:\n",
    "            result = {\"active_test_type\": active_test_type, \"sample_size\": sample_size}\n",
    "            loss_risk = run_one_active_test_risk_estimator(true_losses, expected_losses, seed, sample_size)\n",
    "            result[\"loss\"] = loss_risk\n",
    "            json_object[len(json_object)] = result\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        json.dump(json_object, outfile)\n",
    "        \n",
    "def get_whole_data_set_risk_estimator(true_losses):\n",
    "    return float(true_losses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8d1513d6-22a2-4de7-bb29-3d7f6f9d175e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "base_path = f\"./pro_data/PSPNet_VOC/{split}/\"\n",
    "true_losses = np_read(base_path + \"image_true_losses.npy\")\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_precentage = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "# random_seed_set = [4519, 9524, 5901, 1028, 6382, 5383, 5095, 7635,  890,  608]\n",
    "random_seed_set = [4519, 9524, 5901]\n",
    "result_json_path = \"./results/image_based_active_testing/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d317425-c820-4e5d-a8d1-9c3979671945",
   "metadata": {},
   "source": [
    "## Random Sample risk estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "81d4ead3-b501-4af6-a60f-61d453344f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"random_sample_3_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf2e44-5119-4b5d-bc8e-06ae7047b46c",
   "metadata": {},
   "source": [
    "## Whole data set risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "57c6608b-8fc9-4f0a-89a5-f4f5e982fd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"None.json\"\n",
    "result = {\"active_test_type\": \"None\", \"sample_size\": true_losses.size}\n",
    "result[\"loss\"] = get_whole_data_set_risk_estimator(true_losses)\n",
    "json_object = {}\n",
    "json_object[0] = result\n",
    "with open(file_path, \"w\") as outfile:\n",
    "    json.dump(json_object, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09259650-5cdc-473c-8c38-cd51cc3826f7",
   "metadata": {},
   "source": [
    "## Active Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2b66182-da2b-4437-90a2-6153314558bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
