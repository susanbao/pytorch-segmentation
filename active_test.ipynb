{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd81cf72-4fdc-468f-a1eb-01548c57701c",
   "metadata": {},
   "source": [
    "# Active Testing\n",
    "data stored in ./pro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd0254d-77c6-4946-92aa-2e75a916dc67",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c5306c-2310-4043-82fe-3c234d5f87a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LURE_weights_for_risk_estimator(weights, N):\n",
    "    M = weights.size\n",
    "    if M < N:\n",
    "        m = np.arange(1, M+1)\n",
    "        v = (\n",
    "            1\n",
    "            + (N-M)/(N-m) * (\n",
    "                    1 / ((N-m+1) * weights)\n",
    "                    - 1\n",
    "                    )\n",
    "            )\n",
    "    else:\n",
    "        v = 1\n",
    "\n",
    "    return v\n",
    "\n",
    "def acquire(expected_loss_inputs, samples_num):\n",
    "    assert samples_num <= expected_loss_inputs.size\n",
    "    expected_loss = np.copy(expected_loss_inputs)\n",
    "    # Log-lik can be negative.\n",
    "    # Make all values positive.\n",
    "    if (expected_loss < 0).sum() > 0:\n",
    "        expected_loss += np.abs(expected_loss.min())\n",
    "    \n",
    "    if np.any(np.isnan(expected_loss)):\n",
    "        logging.warning(\n",
    "            'Found NaN values in expected loss, replacing with 0.')\n",
    "        logging.info(f'{expected_loss}')\n",
    "        expected_loss = np.nan_to_num(expected_loss, nan=0)\n",
    "    pick_sample_idxs = np.zeros((samples_num), dtype = int)\n",
    "    idx_array = np.arange(expected_loss.size)\n",
    "    weights = np.zeros((samples_num), dtype = np.single)\n",
    "    uniform_clip_val = 0.2\n",
    "    expected_loss = np.asarray(expected_loss).astype('float64')\n",
    "    for i in range(samples_num):\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        # clip all values less than 10 percent of uniform propability\n",
    "        expected_loss = np.maximum(uniform_clip_val * 1/expected_loss.size, expected_loss)\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        sample = np.random.multinomial(1, expected_loss)\n",
    "        cur_idx = np.where(sample)[0][0]\n",
    "        # cur_idx = np.random.randint(expected_loss.size)\n",
    "        pick_sample_idxs[i] = idx_array[cur_idx]\n",
    "        weights[i] = expected_loss[cur_idx]\n",
    "        selected_mask = np.ones((expected_loss.size), dtype=bool)\n",
    "        selected_mask[cur_idx] = False\n",
    "        expected_loss = expected_loss[selected_mask]\n",
    "        idx_array = idx_array[selected_mask]\n",
    "    return pick_sample_idxs, weights\n",
    "\n",
    "def run_one_random_sample_risk_estimator(true_losses, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    perm = np.random.permutation(true_losses.size)\n",
    "    pick_sample_idxs = perm[:samples_num]\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "    return float(sampled_true_losses.mean())\n",
    "\n",
    "def run_one_active_test_risk_estimator(true_losses, expected_losses, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pick_sample_idxs, weights = acquire(expected_losses, samples_num)\n",
    "    risk_estimator_weights = LURE_weights_for_risk_estimator(weights, expected_losses.size)\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "\n",
    "    loss_risk = (sampled_true_losses * risk_estimator_weights).mean()\n",
    "    return float(loss_risk)\n",
    "\n",
    "def active_testing(file_path, true_losses, expected_losses, active_test_type, display = False):\n",
    "    json_object = {}\n",
    "    for sample_size in sample_size_set:\n",
    "        for seed in random_seed_set:\n",
    "            result = {\"active_test_type\": active_test_type, \"sample_size\": sample_size}\n",
    "            loss_risk = run_one_active_test_risk_estimator(true_losses, expected_losses, seed, sample_size)\n",
    "            result[\"loss\"] = loss_risk\n",
    "            json_object[len(json_object)] = result\n",
    "        if display:\n",
    "            print(f\"Complete simple size : {sample_size}\")\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        json.dump(json_object, outfile)\n",
    "        \n",
    "def get_whole_data_set_risk_estimator(true_losses):\n",
    "    return float(true_losses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c985ec8-ffde-4218-8b45-889a6241bf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "base_path = f\"./pro_data/PSPNet_VOC/{split}/\"\n",
    "data_type = \"region_16\" # image, region_8, region_16\n",
    "if data_type == \"image\":\n",
    "    true_losses = np_read(base_path + \"image_true_losses.npy\")\n",
    "    sample_size_precentage = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045,\n",
    "                          0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08]\n",
    "    result_json_path = \"./results/image_based_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "if data_type == \"image_2\":\n",
    "    true_losses = np_read(base_path + \"image_split_2_2_true_losses.npy\")\n",
    "    sample_size_precentage = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045,\n",
    "                          0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08]\n",
    "    result_json_path = \"./results/image_split_2_2_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "elif data_type == \"region_8\":\n",
    "    true_losses = np_read(base_path + \"region_8_8_true_losses.npy\")\n",
    "    sample_size_precentage = np.linspace(0.00001, 0.0001, 20)\n",
    "    # sample_size_precentage = np.linspace(0.00004, 0.00006, 20)\n",
    "    # sample_size_precentage = np.linspace(0.00001, 0.00005, 2)\n",
    "    result_json_path = \"./results/region_8_8_active_testing/\"\n",
    "    # result_json_path = \"./results/region_8_8_try/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/region_8_8/\"\n",
    "elif data_type == \"region_16\":\n",
    "    true_losses = np_read(base_path + \"region_16_16_true_losses.npy\")\n",
    "    sample_size_precentage = np.linspace(0.0001, 0.001, 20)\n",
    "    result_json_path = \"./results/region_16_16_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/region_16_16/\"\n",
    "    \n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "# random_seed_set = [4519, 9524, 5901, 1028, 6382, 5383, 5095, 7635,  890,  608]\n",
    "random_seed_set = [4519, 9524, 5901]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28f140-6aa1-44fa-b053-ba5185adfe15",
   "metadata": {},
   "source": [
    "## Region VS Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f77b31ae-2a89-4668-ba3c-406897c68d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_json_path = \"./results/image_region_compare/\"\n",
    "sample_size_precentage = np.linspace(0.001, 0.01, 20)\n",
    "true_losses = np_read(base_path + \"image_true_losses.npy\")\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "\n",
    "file_path = result_json_path + \"image_random_sample_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"image random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c85b6cbf-3fca-4795-8b1c-d90f6263445c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = np_read(base_path + \"region_16_16_true_losses.npy\")\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "\n",
    "file_path = result_json_path + \"region_16_16_random_sample_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"region 16x16 random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "179fe5d0-2757-4fd6-b8d6-47c253b17865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = np_read(base_path + \"region_8_8_true_losses.npy\")\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "\n",
    "file_path = result_json_path + \"region_8_8_random_sample_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"region 8x8 random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d317425-c820-4e5d-a8d1-9c3979671945",
   "metadata": {},
   "source": [
    "## Random Sample risk estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "81d4ead3-b501-4af6-a60f-61d453344f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"random_sample_3_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf2e44-5119-4b5d-bc8e-06ae7047b46c",
   "metadata": {},
   "source": [
    "## Whole data set risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "57c6608b-8fc9-4f0a-89a5-f4f5e982fd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"None.json\"\n",
    "result = {\"active_test_type\": \"None\", \"sample_size\": true_losses.size}\n",
    "result[\"loss\"] = get_whole_data_set_risk_estimator(true_losses)\n",
    "json_object = {}\n",
    "json_object[0] = result\n",
    "with open(file_path, \"w\") as outfile:\n",
    "    json.dump(json_object, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bcaf5-dcaa-4a02-9914-6fef889f5c39",
   "metadata": {},
   "source": [
    "## ASE\n",
    "dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "54264344-f66c-4b3c-8e22-d9cc9285a542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## image level\n",
    "ase_loss_path = base_path + \"ase/\"\n",
    "ase_loss = None\n",
    "file_num = len(os.listdir(ase_loss_path))\n",
    "for i in range(file_num):\n",
    "    temp_loss = np_read(ase_loss_path + str(i) + \".npy\")\n",
    "    temp_loss = np.mean(temp_loss, axis=(1, 2))\n",
    "    if ase_loss is None:\n",
    "        ase_loss = temp_loss\n",
    "    else:\n",
    "        ase_loss = np.concatenate((ase_loss, temp_loss))\n",
    "file_path = result_json_path + \"ase_runs.json\"\n",
    "active_testing(file_path, true_losses, ase_loss, \"ASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8ed8d13c-946a-4c34-8af9-dc8dd9141035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 16X16 level\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((30,30))\n",
    "\n",
    "def AveragePool(array):\n",
    "    tensor = torch.from_numpy(array)\n",
    "    tensor = avgpool(tensor)\n",
    "    return tensor.numpy()\n",
    "\n",
    "ase_loss_path = base_path + \"ase/\"\n",
    "ase_loss = None\n",
    "file_num = len(os.listdir(ase_loss_path))\n",
    "for i in range(file_num):\n",
    "    temp_loss = np_read(ase_loss_path + str(i) + \".npy\")\n",
    "    temp_loss = AveragePool(temp_loss).reshape(-1)\n",
    "    if ase_loss is None:\n",
    "        ase_loss = temp_loss\n",
    "    else:\n",
    "        ase_loss = np.concatenate((ase_loss, temp_loss))\n",
    "file_path = result_json_path + \"ase_runs.json\"\n",
    "active_testing(file_path, true_losses, ase_loss, \"ASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "75d8f43b-e61a-41f1-b957-1897ee3691d4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_331370/4079972816.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mase_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcatenate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mase_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtemp_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0mfile_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_json_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"ase_runs.json\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0mactive_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrue_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mase_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ASE\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_331370/2737527201.py\u001b[0m in \u001b[0;36mactive_testing\u001b[0;34m(file_path, true_losses, expected_losses, active_test_type, display)\u001b[0m\n\u001b[1;32m     74\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mseed\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrandom_seed_set\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m\"active_test_type\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mactive_test_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"sample_size\"\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 76\u001b[0;31m             \u001b[0mloss_risk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_one_active_test_risk_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrue_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mseed\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     77\u001b[0m             \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"loss\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss_risk\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     78\u001b[0m             \u001b[0mjson_object\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson_object\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_331370/2737527201.py\u001b[0m in \u001b[0;36mrun_one_active_test_risk_estimator\u001b[0;34m(true_losses, expected_losses, seed, samples_num)\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     63\u001b[0m     \u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 64\u001b[0;31m     \u001b[0mpick_sample_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpected_losses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msamples_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     65\u001b[0m     \u001b[0mrisk_estimator_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLURE_weights_for_risk_estimator\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpected_losses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m     \u001b[0msampled_true_losses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrue_losses\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpick_sample_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_331370/2737527201.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(expected_loss_inputs, samples_num)\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mselected_mask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcur_idx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0mexpected_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpected_loss\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0midx_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0midx_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mselected_mask\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mpick_sample_idxs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "## 8X8 level\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((60,60))\n",
    "\n",
    "def AveragePool(array):\n",
    "    tensor = torch.from_numpy(array)\n",
    "    tensor = avgpool(tensor)\n",
    "    return tensor.numpy()\n",
    "\n",
    "ase_loss_path = base_path + \"ase/\"\n",
    "ase_loss = None\n",
    "file_num = len(os.listdir(ase_loss_path))\n",
    "for i in range(file_num):\n",
    "    temp_loss = np_read(ase_loss_path + str(i) + \".npy\")\n",
    "    temp_loss = AveragePool(temp_loss).reshape(-1)\n",
    "    if ase_loss is None:\n",
    "        ase_loss = temp_loss\n",
    "    else:\n",
    "        ase_loss = np.concatenate((ase_loss, temp_loss))\n",
    "file_path = result_json_path + \"ase_runs.json\"\n",
    "active_testing(file_path, true_losses, ase_loss, \"ASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09259650-5cdc-473c-8c38-cd51cc3826f7",
   "metadata": {},
   "source": [
    "## Image based Active Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b8578533-18c1-49e3-a844-e7f1728e7f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_estimated_loss = np.array(read_one_results(\"../ViT-pytorch/output/ViT-output-PSPNet-VOC-train-ordinal_losses_7600.json\")['losses'])\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs.json\"\n",
    "active_testing(file_path, true_losses, val_estimated_loss, \"ViT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0ced6f91-99bc-4906-bf7d-0613c45467d6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal-new_losses_3600.json\")['losses']).squeeze()\n",
    "# expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "d2b66182-da2b-4437-90a2-6153314558bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-image_losses.json\")['losses']).squeeze()\n",
    "expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_image_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "8473b4c7-52fe-4cbb-99e3-0094875ad207",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"mlp-output-PSPNet-VOC-train-grad_losses.json\")['losses']).squeeze()\n",
    "# expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"mlp_output_train_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"MLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "854915d6-af26-4e02-a7b5-320e1094ac3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-loss-design-entrop_losses.json\")['losses']).squeeze()\n",
    "expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_losses_design_entrop_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "eb1dc8c7-ba42-4480-9902-1e8556e07992",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "expected_losses = np.copy(true_losses)\n",
    "expected_losses[expected_losses<0.01] = 0.01\n",
    "file_path = result_json_path + \"temp_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "2d5ecc96-5744-43ee-b9a5-0b849138b2f2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_true_losses = np_read(\"./pro_data/PSPNet_VOC/train/image_true_losses.npy\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "769308ad-ba6c-4f29-abdd-ef733f3f315d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interval = np.linspace(0, 0.6, num=21)\n",
    "estimate_val = np.copy(true_losses)\n",
    "for i in range(0, interval.shape[0]-1):\n",
    "    estimate_val[true_losses>interval[i]] = (interval[i] + interval[i+1])/2\n",
    "file_path = result_json_path + \"ordinal_with_true_loss_runs.json\"\n",
    "active_testing(file_path, true_losses, estimate_val, \"ordinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636953f8-a34b-4973-93fe-19f0bed042c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image split 2x2\n",
    "val_estimated_loss = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal-image-split-2x2_losses_8000.json\")['losses'])\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs.json\"\n",
    "active_testing(file_path, true_losses, val_estimated_loss, \"ViT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad23329-e1fc-49a9-b024-b241dc76d3f5",
   "metadata": {},
   "source": [
    "## Region-based Active Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "9109d4a0-e80b-414c-897a-248cfe7ab1e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal_losses_7600.json\")['losses']).squeeze()\n",
    "# expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10f58ec2-a5e6-4af9-95e5-ae683c5bc1da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal-new_losses_6000.json\")['losses']).squeeze()\n",
    "# expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f173c3d-9ffc-4456-949a-d89324426f04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 52\n",
      "Complete simple size : 76\n",
      "Complete simple size : 101\n",
      "Complete simple size : 126\n",
      "Complete simple size : 151\n",
      "Complete simple size : 175\n",
      "Complete simple size : 200\n",
      "Complete simple size : 225\n",
      "Complete simple size : 249\n",
      "Complete simple size : 274\n",
      "Complete simple size : 299\n",
      "Complete simple size : 323\n",
      "Complete simple size : 348\n",
      "Complete simple size : 373\n",
      "Complete simple size : 398\n",
      "Complete simple size : 422\n",
      "Complete simple size : 447\n",
      "Complete simple size : 472\n",
      "Complete simple size : 496\n",
      "Complete simple size : 521\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal-8x8-grad-new_losses_6200.json\")['losses']).squeeze()\n",
    "# expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs_try.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10f23e-e04f-4d0a-911a-509026239117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
