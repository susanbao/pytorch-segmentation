{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd81cf72-4fdc-468f-a1eb-01548c57701c",
   "metadata": {},
   "source": [
    "# Active Testing\n",
    "data stored in ./pro_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffd0254d-77c6-4946-92aa-2e75a916dc67",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/sas20048/anaconda/envs/at_det/lib/python3.7/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import datetime\n",
    "import json\n",
    "import random\n",
    "import time\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "import numpy as np\n",
    "import torch\n",
    "import pickle\n",
    "import copy\n",
    "import random\n",
    "from utils.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f5c5306c-2310-4043-82fe-3c234d5f87a6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LURE_weights_for_risk_estimator(weights, N):\n",
    "    M = weights.size\n",
    "    if M < N:\n",
    "        m = np.arange(1, M+1)\n",
    "        v = (\n",
    "            1\n",
    "            + (N-M)/(N-m) * (\n",
    "                    1 / ((N-m+1) * weights)\n",
    "                    - 1\n",
    "                    )\n",
    "            )\n",
    "    else:\n",
    "        v = 1\n",
    "\n",
    "    return v\n",
    "\n",
    "def acquire(expected_loss_inputs, samples_num):\n",
    "    assert samples_num <= expected_loss_inputs.size\n",
    "    expected_loss = np.copy(expected_loss_inputs)\n",
    "    # Log-lik can be negative.\n",
    "    # Make all values positive.\n",
    "    if (expected_loss < 0).sum() > 0:\n",
    "        expected_loss += np.abs(expected_loss.min())\n",
    "    \n",
    "    if np.any(np.isnan(expected_loss)):\n",
    "        logging.warning(\n",
    "            'Found NaN values in expected loss, replacing with 0.')\n",
    "        logging.info(f'{expected_loss}')\n",
    "        expected_loss = np.nan_to_num(expected_loss, nan=0)\n",
    "    pick_sample_idxs = np.zeros((samples_num), dtype = int)\n",
    "    idx_array = np.arange(expected_loss.size)\n",
    "    weights = np.zeros((samples_num), dtype = np.single)\n",
    "    uniform_clip_val = 0.2\n",
    "    expected_loss = np.asarray(expected_loss).astype('float64')\n",
    "    for i in range(samples_num):\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        # clip all values less than 10 percent of uniform propability\n",
    "        expected_loss = np.maximum(uniform_clip_val * 1/expected_loss.size, expected_loss)\n",
    "        expected_loss /= expected_loss.sum()\n",
    "        sample = np.random.multinomial(1, expected_loss)\n",
    "        cur_idx = np.where(sample)[0][0]\n",
    "        # cur_idx = np.random.randint(expected_loss.size)\n",
    "        pick_sample_idxs[i] = idx_array[cur_idx]\n",
    "        weights[i] = expected_loss[cur_idx]\n",
    "        selected_mask = np.ones((expected_loss.size), dtype=bool)\n",
    "        selected_mask[cur_idx] = False\n",
    "        expected_loss = expected_loss[selected_mask]\n",
    "        idx_array = idx_array[selected_mask]\n",
    "    return pick_sample_idxs, weights\n",
    "\n",
    "def run_one_random_sample_risk_estimator(true_losses, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    perm = np.random.permutation(true_losses.size)\n",
    "    pick_sample_idxs = perm[:samples_num]\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "    return float(sampled_true_losses.mean())\n",
    "\n",
    "def run_one_active_test_risk_estimator(true_losses, expected_losses, seed, samples_num):\n",
    "    torch.manual_seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    pick_sample_idxs, weights = acquire(expected_losses, samples_num)\n",
    "    risk_estimator_weights = LURE_weights_for_risk_estimator(weights, expected_losses.size)\n",
    "    sampled_true_losses = true_losses[pick_sample_idxs]\n",
    "\n",
    "    loss_risk = (sampled_true_losses * risk_estimator_weights).mean()\n",
    "    return float(loss_risk)\n",
    "\n",
    "def active_testing(file_path, true_losses, expected_losses, active_test_type, display = False):\n",
    "    json_object = {}\n",
    "    for sample_size in sample_size_set:\n",
    "        for seed in random_seed_set:\n",
    "            result = {\"active_test_type\": active_test_type, \"sample_size\": sample_size}\n",
    "            loss_risk = run_one_active_test_risk_estimator(true_losses, expected_losses, seed, sample_size)\n",
    "            result[\"loss\"] = loss_risk\n",
    "            json_object[len(json_object)] = result\n",
    "        if display:\n",
    "            print(f\"Complete simple size : {sample_size}\")\n",
    "    with open(file_path, \"w\") as outfile:\n",
    "        json.dump(json_object, outfile)\n",
    "        \n",
    "def get_whole_data_set_risk_estimator(true_losses):\n",
    "    return float(true_losses.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7c985ec8-ffde-4218-8b45-889a6241bf73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "split = \"val\"\n",
    "# PSPNet_VOC, UNet_COCO10k, UNet_VOC, DeepLab_VOC, FCN_VOC, SEGNet_VOC, PSPNet_CITY\n",
    "model_dataset = \"DeepLab_VOC\"\n",
    "base_path = f\"./pro_data/{model_dataset}/{split}/\"\n",
    "data_type = \"image\" # image, region_8, region_16\n",
    "check_folder_exist(f\"./results/{model_dataset}\")\n",
    "if data_type == \"image\":\n",
    "    true_losses = np_read(base_path + \"image_true_losses.npy\")\n",
    "    sample_size_precentage = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045,\n",
    "                          0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08]\n",
    "    result_json_path = f\"./results/{model_dataset}/image_based_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "if data_type == \"image_2\":\n",
    "    true_losses = np_read(base_path + \"image_split_2_2_true_losses.npy\")\n",
    "    sample_size_precentage = [0.001, 0.002, 0.003, 0.004, 0.005, 0.006, 0.007, 0.008, 0.009, 0.01, 0.015, 0.02, 0.025, 0.03, 0.035, 0.04, 0.045,\n",
    "                          0.05, 0.055, 0.06, 0.065, 0.07, 0.075, 0.08]\n",
    "    result_json_path = f\"./results/{model_dataset}/image_split_2_2_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "elif data_type == \"region_8\":\n",
    "    true_losses = np_read(base_path + \"region_8_8_true_losses.npy\")\n",
    "    sample_size_precentage = np.linspace(0.00001, 0.0001, 20)\n",
    "    # sample_size_precentage = np.linspace(0.00004, 0.00006, 20)\n",
    "    # sample_size_precentage = np.linspace(0.00001, 0.00005, 2)\n",
    "    result_json_path = f\"./results/{model_dataset}/region_8_8_active_testing/\"\n",
    "    # result_json_path = \"./results/region_8_8_try/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/region_8_8/\"\n",
    "elif data_type == \"region_16\":\n",
    "    true_losses = np_read(base_path + \"region_16_16_true_losses.npy\")\n",
    "    sample_size_precentage = np.linspace(0.0001, 0.001, 20)\n",
    "    result_json_path = f\"./results/{model_dataset}/region_16_16_active_testing/\"\n",
    "    # vit_base_path = \"../ViT-pytorch/output/region_16_16/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "elif data_type == \"region_60\":\n",
    "    true_losses = np_read(base_path + \"region_60_60_true_losses.npy\")\n",
    "    sample_size_precentage = np.linspace(0.0001, 0.001, 20)\n",
    "    result_json_path = f\"./results/{model_dataset}/region_60_60_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "elif data_type == \"region_30\":\n",
    "    true_losses = np_read(base_path + \"region_30_30_true_losses.npy\")\n",
    "    sample_size_precentage = np.linspace(0.0001, 0.001, 20)\n",
    "    result_json_path = f\"./results/{model_dataset}/region_30_30_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "elif data_type == \"region_32\":\n",
    "    true_losses = np_read(base_path + \"region_32_32_true_losses.npy\")\n",
    "    sample_size_precentage = np.linspace(0.0001, 0.001, 20)\n",
    "    result_json_path = f\"./results/{model_dataset}/region_32_32_active_testing/\"\n",
    "    vit_base_path = \"../ViT-pytorch/output/\"\n",
    "\n",
    "check_folder_exist(result_json_path)\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "# random_seed_set = [4519, 9524, 5901, 1028, 6382, 5383, 5095, 7635,  890,  608]\n",
    "random_seed_set = [4519, 9524, 5901]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef28f140-6aa1-44fa-b053-ba5185adfe15",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Region VS Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "f77b31ae-2a89-4668-ba3c-406897c68d9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "result_json_path = \"./results/image_region_compare/\"\n",
    "sample_size_precentage = np.linspace(0.001, 0.01, 20)\n",
    "true_losses = np_read(base_path + \"image_true_losses.npy\")\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "\n",
    "file_path = result_json_path + \"image_random_sample_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"image random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c85b6cbf-3fca-4795-8b1c-d90f6263445c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = np_read(base_path + \"region_16_16_true_losses.npy\")\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "\n",
    "file_path = result_json_path + \"region_16_16_random_sample_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"region 16x16 random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "179fe5d0-2757-4fd6-b8d6-47c253b17865",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "true_losses = np_read(base_path + \"region_8_8_true_losses.npy\")\n",
    "box_labels_nums = true_losses.shape[0]\n",
    "sample_size_set = (np.array(sample_size_precentage) * box_labels_nums).astype(int).tolist()\n",
    "\n",
    "file_path = result_json_path + \"region_8_8_random_sample_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"region 8x8 random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d317425-c820-4e5d-a8d1-9c3979671945",
   "metadata": {},
   "source": [
    "## Random Sample risk estimation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "81d4ead3-b501-4af6-a60f-61d453344f79",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"random_sample_3_runs.json\"\n",
    "json_object = {}\n",
    "for sample_size in sample_size_set:\n",
    "    for seed in random_seed_set:\n",
    "        result = {\"active_test_type\": \"random sample\", \"sample_size\": sample_size}\n",
    "        loss_risk = run_one_random_sample_risk_estimator(true_losses, seed, sample_size)\n",
    "        result[\"loss\"] = float(loss_risk)\n",
    "        json_object[len(json_object)] = result\n",
    "write_one_results(json_object, file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2adf2e44-5119-4b5d-bc8e-06ae7047b46c",
   "metadata": {},
   "source": [
    "## Whole data set risk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "57c6608b-8fc9-4f0a-89a5-f4f5e982fd34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = result_json_path + \"None.json\"\n",
    "result = {\"active_test_type\": \"None\", \"sample_size\": true_losses.size}\n",
    "result[\"loss\"] = get_whole_data_set_risk_estimator(true_losses)\n",
    "json_object = {}\n",
    "json_object[0] = result\n",
    "with open(file_path, \"w\") as outfile:\n",
    "    json.dump(json_object, outfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99bcaf5-dcaa-4a02-9914-6fef889f5c39",
   "metadata": {
    "tags": []
   },
   "source": [
    "## ASE\n",
    "dropout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "54264344-f66c-4b3c-8e22-d9cc9285a542",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## image level\n",
    "ase_loss_path =  \"./pro_data/UNet_VOC_ASE/ase/\"\n",
    "ase_loss = None\n",
    "file_num = len(os.listdir(ase_loss_path))\n",
    "for i in range(file_num):\n",
    "    temp_loss = np_read(ase_loss_path + str(i) + \".npy\")\n",
    "    temp_loss = np.mean(temp_loss, axis=(1, 2))\n",
    "    if ase_loss is None:\n",
    "        ase_loss = temp_loss\n",
    "    else:\n",
    "        ase_loss = np.concatenate((ase_loss, temp_loss))\n",
    "file_path = result_json_path + \"ase_runs.json\"\n",
    "active_testing(file_path, true_losses, ase_loss, \"ASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8ed8d13c-946a-4c34-8af9-dc8dd9141035",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 16X16 level\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((30,30))\n",
    "\n",
    "def AveragePool(array):\n",
    "    tensor = torch.from_numpy(array)\n",
    "    tensor = avgpool(tensor)\n",
    "    return tensor.numpy()\n",
    "\n",
    "ase_loss_path =  \"./pro_data/UNet_VOC_ASE/ase/\"\n",
    "ase_loss = None\n",
    "file_num = len(os.listdir(ase_loss_path))\n",
    "for i in range(file_num):\n",
    "    temp_loss = np_read(ase_loss_path + str(i) + \".npy\")\n",
    "    temp_loss = AveragePool(temp_loss).reshape(-1)\n",
    "    if ase_loss is None:\n",
    "        ase_loss = temp_loss\n",
    "    else:\n",
    "        ase_loss = np.concatenate((ase_loss, temp_loss))\n",
    "file_path = result_json_path + \"ase_runs.json\"\n",
    "active_testing(file_path, true_losses, ase_loss, \"ASE\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d8f43b-e61a-41f1-b957-1897ee3691d4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "## 8X8 level\n",
    "avgpool = torch.nn.AdaptiveAvgPool2d((60,60))\n",
    "\n",
    "def AveragePool(array):\n",
    "    tensor = torch.from_numpy(array)\n",
    "    tensor = avgpool(tensor)\n",
    "    return tensor.numpy()\n",
    "\n",
    "ase_loss_path =  \"./pro_data/UNet_VOC_ASE/ase/\"\n",
    "ase_loss = None\n",
    "file_num = len(os.listdir(ase_loss_path))\n",
    "for i in range(file_num):\n",
    "    temp_loss = np_read(ase_loss_path + str(i) + \".npy\")\n",
    "    temp_loss = AveragePool(temp_loss).reshape(-1)\n",
    "    if ase_loss is None:\n",
    "        ase_loss = temp_loss\n",
    "    else:\n",
    "        ase_loss = np.concatenate((ase_loss, temp_loss))\n",
    "file_path = result_json_path + \"ase_runs.json\"\n",
    "active_testing(file_path, true_losses, ase_loss, \"ASE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09259650-5cdc-473c-8c38-cd51cc3826f7",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Image based Active Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b8578533-18c1-49e3-a844-e7f1728e7f34",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "train_step = 10000\n",
    "val_estimated_loss = np.array(read_one_results(f\"../ViT-pytorch/output/ViT_{model_dataset}_all_losses_{train_step}.json\")['losses'])\n",
    "file_path = result_json_path + f\"ViT_all_runs_{train_step}.json\"\n",
    "active_testing(file_path, true_losses, val_estimated_loss, \"ViT all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "769308ad-ba6c-4f29-abdd-ef733f3f315d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "interval = np.linspace(0, 0.6, num=21)\n",
    "estimate_val = np.copy(true_losses)\n",
    "for i in range(0, interval.shape[0]-1):\n",
    "    estimate_val[true_losses>interval[i]] = (interval[i] + interval[i+1])/2\n",
    "file_path = result_json_path + \"ordinal_with_true_loss_runs.json\"\n",
    "active_testing(file_path, true_losses, estimate_val, \"ordinal\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "636953f8-a34b-4973-93fe-19f0bed042c2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# image split 2x2\n",
    "val_estimated_loss = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal-image-split-2x2_losses_8000.json\")['losses'])\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs.json\"\n",
    "active_testing(file_path, true_losses, val_estimated_loss, \"ViT\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad23329-e1fc-49a9-b024-b241dc76d3f5",
   "metadata": {},
   "source": [
    "## Region-based Active Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1ddf9cfd-56cc-488c-bf1c-0f414062a271",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "# 16X16\n",
    "train_step = 20000\n",
    "expected_losses = np.array(read_one_results(vit_base_path + f\"ViT_{model_dataset}_region_losses_{train_step}.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + f\"ViT_region_runs_{train_step}.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT region\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9109d4a0-e80b-414c-897a-248cfe7ab1e9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "# 16X16\n",
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT_UNet_VOC_class_70_losses_20000.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + \"ViT_UNet_VOC_class_70_runs_20000.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT class 70\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e2972341-c6bf-4bbf-ac75-4ad1e197f90f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT_UNet_VOC_class_80_losses_20000.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + \"ViT_UNet_VOC_class_80_runs_20000.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT class 80\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ef3e0c44-49e3-4a4f-bea1-1cd3461a8582",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT_UNet_VOC_class_90_losses_20000.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + \"ViT_UNet_VOC_class_90_runs_20000.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT class 90\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "83e52f78-3870-4ab1-a2a0-995402945f23",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT_UNet_VOC_class_30_losses_20000.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + \"ViT_UNet_VOC_class_30_runs_20000.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT class 30\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdd015c9-0a10-45b3-9709-065392f6386d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT_UNet_VOC_class_40_losses_20000.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + \"ViT_UNet_VOC_class_40_runs_20000.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT class 40\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bc0dcee4-00f9-4020-aaf0-555ea9c2648e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT_UNet_VOC_class_60_losses_20000.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + \"ViT_UNet_VOC_class_60_runs_20000.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT class 60\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "803da0a2-574f-4721-9458-14724c4a6d28",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 130\n",
      "Complete simple size : 192\n",
      "Complete simple size : 253\n",
      "Complete simple size : 315\n",
      "Complete simple size : 377\n",
      "Complete simple size : 439\n",
      "Complete simple size : 501\n",
      "Complete simple size : 562\n",
      "Complete simple size : 624\n",
      "Complete simple size : 686\n",
      "Complete simple size : 748\n",
      "Complete simple size : 809\n",
      "Complete simple size : 871\n",
      "Complete simple size : 933\n",
      "Complete simple size : 995\n",
      "Complete simple size : 1057\n",
      "Complete simple size : 1118\n",
      "Complete simple size : 1180\n",
      "Complete simple size : 1242\n",
      "Complete simple size : 1304\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT_UNet_VOC_range_region_losses_20000.json\")['losses']).squeeze()\n",
    "file_path = result_json_path + \"ViT_range_region_runs_20000.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT region\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3039e2f9-a848-45e3-9f2b-a88612375e32",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10f58ec2-a5e6-4af9-95e5-ae683c5bc1da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 52\n",
      "Complete simple size : 76\n",
      "Complete simple size : 101\n",
      "Complete simple size : 126\n",
      "Complete simple size : 151\n",
      "Complete simple size : 175\n",
      "Complete simple size : 200\n",
      "Complete simple size : 225\n",
      "Complete simple size : 249\n",
      "Complete simple size : 274\n",
      "Complete simple size : 299\n",
      "Complete simple size : 323\n",
      "Complete simple size : 348\n",
      "Complete simple size : 373\n",
      "Complete simple size : 398\n",
      "Complete simple size : 422\n",
      "Complete simple size : 447\n",
      "Complete simple size : 472\n",
      "Complete simple size : 496\n",
      "Complete simple size : 521\n"
     ]
    }
   ],
   "source": [
    "# 8X8\n",
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal-8x8-grad_losses_40000.json\")['losses']).squeeze()\n",
    "# expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f173c3d-9ffc-4456-949a-d89324426f04",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete simple size : 52\n",
      "Complete simple size : 76\n",
      "Complete simple size : 101\n",
      "Complete simple size : 126\n",
      "Complete simple size : 151\n",
      "Complete simple size : 175\n",
      "Complete simple size : 200\n",
      "Complete simple size : 225\n",
      "Complete simple size : 249\n",
      "Complete simple size : 274\n",
      "Complete simple size : 299\n",
      "Complete simple size : 323\n",
      "Complete simple size : 348\n",
      "Complete simple size : 373\n",
      "Complete simple size : 398\n",
      "Complete simple size : 422\n",
      "Complete simple size : 447\n",
      "Complete simple size : 472\n",
      "Complete simple size : 496\n",
      "Complete simple size : 521\n"
     ]
    }
   ],
   "source": [
    "expected_losses = np.array(read_one_results(vit_base_path + \"ViT-output-PSPNet-VOC-train-ordinal-8x8-loss-order_checkpoint_40000.json\")['losses']).squeeze()\n",
    "# expected_losses = np.exp(expected_losses)\n",
    "file_path = result_json_path + \"ViT_output_train_ordinal_runs_try.json\"\n",
    "active_testing(file_path, true_losses, expected_losses, \"ViT\", display=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a10f23e-e04f-4d0a-911a-509026239117",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
